<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<title>Class separation • biplotEZ</title>
<!-- favicons --><link rel="icon" type="image/png" sizes="96x96" href="../favicon-96x96.png">
<link rel="icon" type="”image/svg+xml”" href="../favicon.svg">
<link rel="apple-touch-icon" sizes="180x180" href="../apple-touch-icon.png">
<link rel="icon" sizes="any" href="../favicon.ico">
<link rel="manifest" href="../site.webmanifest">
<script src="../deps/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<link href="../deps/bootstrap-5.3.1/bootstrap.min.css" rel="stylesheet">
<script src="../deps/bootstrap-5.3.1/bootstrap.bundle.min.js"></script><link href="../deps/font-awesome-6.5.2/css/all.min.css" rel="stylesheet">
<link href="../deps/font-awesome-6.5.2/css/v4-shims.min.css" rel="stylesheet">
<script src="../deps/headroom-0.11.0/headroom.min.js"></script><script src="../deps/headroom-0.11.0/jQuery.headroom.min.js"></script><script src="../deps/bootstrap-toc-1.0.1/bootstrap-toc.min.js"></script><script src="../deps/clipboard.js-2.0.11/clipboard.min.js"></script><script src="../deps/search-1.0.0/autocomplete.jquery.min.js"></script><script src="../deps/search-1.0.0/fuse.min.js"></script><script src="../deps/search-1.0.0/mark.min.js"></script><!-- pkgdown --><script src="../pkgdown.js"></script><meta property="og:title" content="Class separation">
</head>
<body>
    <a href="#main" class="visually-hidden-focusable">Skip to contents</a>


    <nav class="navbar navbar-expand-lg fixed-top bg-light" data-bs-theme="light" aria-label="Site navigation"><div class="container">

    <a class="navbar-brand me-2" href="../index.html">biplotEZ</a>

    <small class="nav-text text-muted me-auto" data-bs-toggle="tooltip" data-bs-placement="bottom" title="">2.3</small>


    <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbar" aria-controls="navbar" aria-expanded="false" aria-label="Toggle navigation">
      <span class="navbar-toggler-icon"></span>
    </button>

    <div id="navbar" class="collapse navbar-collapse ms-3">
      <ul class="navbar-nav me-auto">
<li class="nav-item"><a class="nav-link" href="../articles/biplotEZ.html">Get started</a></li>
<li class="nav-item"><a class="nav-link" href="../reference/index.html">Reference</a></li>
<li class="nav-item dropdown">
  <button class="nav-link dropdown-toggle" type="button" id="dropdown-articles" data-bs-toggle="dropdown" aria-expanded="false" aria-haspopup="true">Articles</button>
  <ul class="dropdown-menu" aria-labelledby="dropdown-articles">
<li><a class="dropdown-item" href="../articles/biplotEZ.html">biplotEZ</a></li>
    <li><a class="dropdown-item" href="../articles/biplotEZ_enhancements.html">biplotEZ enhancements</a></li>
    <li><a class="dropdown-item" href="../articles/Biplots_in_1D.html">One dimensional biplots</a></li>
    <li><a class="dropdown-item" href="../articles/Biplots_in_2D.html">Two dimensional biplots</a></li>
    <li><a class="dropdown-item" href="../articles/Biplots_in_3D.html">Three dimensional biplots</a></li>
  </ul>
</li>
      </ul>
<ul class="navbar-nav">
<li class="nav-item"><form class="form-inline" role="search">
 <input class="form-control" type="search" name="search-input" id="search-input" autocomplete="off" aria-label="Search site" placeholder="Search for" data-search-index="../search.json">
</form></li>
      </ul>
</div>


  </div>
</nav><div class="container template-article">




<div class="row">
  <main id="main" class="col-md-9"><div class="page-header">
      <img src="../logo.png" class="logo" alt=""><h1>Class separation</h1>
            
      

      <div class="d-none name"><code>Class_separation.Rmd</code></div>
    </div>

    
    
<div class="sourceCode" id="cb1"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html" class="external-link">library</a></span><span class="op">(</span><span class="va">biplotEZ</span><span class="op">)</span></span>
<span><span class="co">#&gt; Welcome to biplotEZ! </span></span>
<span><span class="co">#&gt; This package is used to construct biplots </span></span>
<span><span class="co">#&gt; Run ?biplot or vignette() for more information</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Attaching package: 'biplotEZ'</span></span>
<span><span class="co">#&gt; The following object is masked from 'package:stats':</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt;     biplot</span></span></code></pre></div>
<p>This vignette deals with biplots for separating classes. Topics
discussed are</p>
<ul>
<li>CVA (Canonical variate analysis) biplots</li>
<li>AoD (Analysis of Distance) biplots</li>
<li>Classification biplots</li>
</ul>
<div class="section level2">
<h2 id="what-is-a-cva-biplot">What is a CVA biplot<a class="anchor" aria-label="anchor" href="#what-is-a-cva-biplot"></a>
</h2>
<p>Consider a data matrix
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>𝐗</mi><mo>:</mo><mi>n</mi><mo>×</mo><mi>p</mi></mrow><annotation encoding="application/x-tex">\mathbf{X}:n \times p</annotation></semantics></math>
containing data on
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>n</mi><annotation encoding="application/x-tex">n</annotation></semantics></math>
objects and
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>p</mi><annotation encoding="application/x-tex">p</annotation></semantics></math>
variables. In addition, a vector
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>𝐠</mi><mo>:</mo><mi>n</mi><mo>×</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">\mathbf{g}:n \times 1</annotation></semantics></math>
contains information on class membership of each observation. Let
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>G</mi><annotation encoding="application/x-tex">G</annotation></semantics></math>
indicate the total number of classes. CVA is closely related to linear
discriminant anlaysis, in that the
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>p</mi><annotation encoding="application/x-tex">p</annotation></semantics></math>
variables are transformed to
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>p</mi><annotation encoding="application/x-tex">p</annotation></semantics></math>
new variables, called canonical variates, such that the classes are
optimally separated in the canonical space. By optimally separated, we
mean maximising the between class variance, relative to the within class
variance. This can be formulated as follows:</p>
<p>Let
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>𝐆</mi><mo>:</mo><mi>n</mi><mo>×</mo><mi>G</mi></mrow><annotation encoding="application/x-tex">\mathbf{G}:n \times G</annotation></semantics></math>
be an indicator matrix with
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>g</mi><mrow><mi>i</mi><mi>j</mi></mrow></msub><mo>=</mo><mn>0</mn></mrow><annotation encoding="application/x-tex">g_{ij} = 0</annotation></semantics></math>
unless observation
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>i</mi><annotation encoding="application/x-tex">i</annotation></semantics></math>
belongs to class
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>j</mi><annotation encoding="application/x-tex">j</annotation></semantics></math>
and then
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>g</mi><mrow><mi>i</mi><mi>j</mi></mrow></msub><mo>=</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">g_{ij} = 1</annotation></semantics></math>.
The matrix
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>𝐆</mi><mi mathvariant="bold">′</mi><mi>𝐆</mi></mrow><annotation encoding="application/x-tex">\mathbf{G'G}</annotation></semantics></math>
is a diagonal matrix containing the number of observations per class on
the diagonal. We can form the matrix of class means
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mover><mi>𝐗</mi><mo accent="true">‾</mo></mover><mo>:</mo><mi>G</mi><mo>×</mo><mi>p</mi><mo>=</mo><msup><mrow><mo stretchy="true" form="prefix">(</mo><mrow><mi>𝐆</mi><mi mathvariant="bold">′</mi><mi>𝐆</mi></mrow><mo stretchy="true" form="postfix">)</mo></mrow><mrow><mi>−</mi><mn>1</mn></mrow></msup><mrow><mi>𝐆</mi><mi mathvariant="bold">′</mi><mi>𝐗</mi></mrow></mrow><annotation encoding="application/x-tex">\bar{\mathbf{X}}:G \times p = (\mathbf{G'G})^{-1} \mathbf{G'X}</annotation></semantics></math>.
With the usual analysis of variance the total variance can be decomposed
into a between class variance and within class variance:</p>
<p><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>𝐓</mi><mo>=</mo><mi>𝐁</mi><mo>+</mo><mi>𝐖</mi></mrow><annotation encoding="application/x-tex">
\mathbf{T} = \mathbf{B} + \mathbf{W}
</annotation></semantics></math></p>
<p><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mrow><mi>𝐗</mi><mi mathvariant="bold">′</mi><mi>𝐗</mi></mrow><mo>=</mo><mrow><mover><mi>𝐗</mi><mo accent="true">‾</mo></mover><mi mathvariant="bold">′</mi><mi>𝐂</mi><mover><mi>𝐗</mi><mo accent="true">‾</mo></mover></mrow><mo>+</mo><mrow><mi>𝐗</mi><mi mathvariant="bold">′</mi><mrow><mo stretchy="true" form="prefix" mathvariant="bold">[</mo><mi>𝐈</mi><mo mathvariant="bold">−</mo><mi>𝐆</mi><msup><mrow><mo stretchy="true" form="prefix" mathvariant="bold">(</mo><mi>𝐆</mi><mi mathvariant="bold">′</mi><mi>𝐆</mi><mo stretchy="true" form="postfix" mathvariant="bold">)</mo></mrow><mrow><mi mathvariant="bold">−</mi><mn>𝟏</mn></mrow></msup><mi>𝐂</mi><msup><mrow><mo stretchy="true" form="prefix" mathvariant="bold">(</mo><mi>𝐆</mi><mi mathvariant="bold">′</mi><mi>𝐆</mi><mo stretchy="true" form="postfix" mathvariant="bold">)</mo></mrow><mrow><mi mathvariant="bold">−</mi><mn>𝟏</mn></mrow></msup><mi>𝐆</mi><mi mathvariant="bold">′</mi><mo stretchy="true" form="postfix" mathvariant="bold">]</mo></mrow><mi>𝐗</mi></mrow></mrow><annotation encoding="application/x-tex">
\mathbf{X'X} = \mathbf{\bar{\mathbf{X}}'C \bar{\mathbf{X}}} + \mathbf{X' [I - G(G'G)^{-1}C(G'G)^{-1}G'] X}
</annotation></semantics></math></p>
<p>The default choice for the centring matrix
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>𝐂</mi><mo mathvariant="bold">=</mo><mi>𝐆</mi><mi mathvariant="bold">′</mi><mi>𝐆</mi></mrow><annotation encoding="application/x-tex">\mathbf{C = G'G}</annotation></semantics></math>
leads to the simplification</p>
<p><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mrow><mi>𝐗</mi><mi mathvariant="bold">′</mi><mi>𝐗</mi></mrow><mo>=</mo><mrow><mover><mi>𝐗</mi><mo accent="true">‾</mo></mover><mi mathvariant="bold">′</mi><mi>𝐆</mi><mi mathvariant="bold">′</mi><mi>𝐆</mi><mover><mi>𝐗</mi><mo accent="true">‾</mo></mover></mrow><mo>+</mo><mrow><mi>𝐗</mi><mi mathvariant="bold">′</mi><mrow><mo stretchy="true" form="prefix" mathvariant="bold">[</mo><mi>𝐈</mi><mo mathvariant="bold">−</mo><mi>𝐆</mi><msup><mrow><mo stretchy="true" form="prefix" mathvariant="bold">(</mo><mi>𝐆</mi><mi mathvariant="bold">′</mi><mi>𝐆</mi><mo stretchy="true" form="postfix" mathvariant="bold">)</mo></mrow><mrow><mi mathvariant="bold">−</mi><mn>𝟏</mn></mrow></msup><mi>𝐆</mi><mi mathvariant="bold">′</mi><mo stretchy="true" form="postfix" mathvariant="bold">]</mo></mrow><mi>𝐗</mi></mrow><mi>.</mi></mrow><annotation encoding="application/x-tex">
\mathbf{X'X} = \mathbf{\bar{\mathbf{X}}'G'G \bar{\mathbf{X}}} + \mathbf{X' [I - G(G'G)^{-1}G'] X}.
</annotation></semantics></math></p>
<p>Other options are
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>𝐂</mi><mo mathvariant="bold">=</mo><mi>𝐈</mi></mrow><annotation encoding="application/x-tex">\mathbf{C = I}</annotation></semantics></math>
and
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>𝐂</mi><mo>=</mo><mrow><mo stretchy="true" form="prefix">(</mo><msub><mi>𝐈</mi><mi>G</mi></msub><mo>−</mo><mfrac><mn>1</mn><mi>G</mi></mfrac><mrow><mn>𝟏𝟏</mn><mi mathvariant="bold">′</mi></mrow><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">\mathbf{C} = (\mathbf{I}_G - \frac{1}{G}\mathbf{11'})</annotation></semantics></math>.
To find the canonical variates we want to maximise the ratio</p>
<p><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mfrac><mrow><mi>𝐦</mi><mi mathvariant="bold">′</mi><mi>𝐁</mi><mi>𝐦</mi></mrow><mrow><mi>𝐦</mi><mi mathvariant="bold">′</mi><mi>𝐖</mi><mi>𝐦</mi></mrow></mfrac><annotation encoding="application/x-tex">
\frac{\mathbf{m'Bm}}{\mathbf{m'Wm}}
</annotation></semantics></math></p>
<p>subject to
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mrow><mi>𝐦</mi><mi mathvariant="bold">′</mi><mi>𝐖</mi><mi>𝐦</mi></mrow><mo>=</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">\mathbf{m'Wm} = 1</annotation></semantics></math>.
It can be shown that this leads to the following equivalent eigen
equations:</p>
<p><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>𝐖</mi><mrow><mi>−</mi><mn>1</mn></mrow></msup><mrow><mi>𝐁</mi><mi>𝐌</mi></mrow><mo>=</mo><mrow><mi>𝐌</mi><mi>𝚲</mi></mrow></mrow><annotation encoding="application/x-tex">
\mathbf{W}^{-1}\mathbf{BM} = \mathbf{M \Lambda} \tag{1}
</annotation></semantics></math></p>
<p><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mrow><mi>𝐁</mi><mi>𝐌</mi></mrow><mo>=</mo><mrow><mi>𝐖</mi><mi>𝐌</mi><mi>𝚲</mi></mrow></mrow><annotation encoding="application/x-tex">
\mathbf{BM} = \mathbf{WM \Lambda}
</annotation></semantics></math></p>
<p><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mrow><mo stretchy="true" form="prefix">(</mo><msup><mi>𝐖</mi><mrow><mi>−</mi><mfrac><mn>1</mn><mn>2</mn></mfrac></mrow></msup><mi>𝐁</mi><msup><mi>𝐖</mi><mrow><mi>−</mi><mfrac><mn>1</mn><mn>2</mn></mfrac></mrow></msup><mo stretchy="true" form="postfix">)</mo></mrow><mi>𝐌</mi><mo>=</mo><mrow><mo stretchy="true" form="prefix">(</mo><msup><mi>𝐖</mi><mrow><mi>−</mi><mfrac><mn>1</mn><mn>2</mn></mfrac></mrow></msup><mi>𝐌</mi><mo stretchy="true" form="postfix">)</mo></mrow><mi>𝚲</mi></mrow><annotation encoding="application/x-tex">
(\mathbf{W}^{-\frac{1}{2}} \mathbf{B} \mathbf{W}^{-\frac{1}{2}}) \mathbf{M} = (\mathbf{W}^{-\frac{1}{2}} \mathbf{M}) \mathbf{\Lambda}
</annotation></semantics></math></p>
<p>with
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mrow><mi>𝐌</mi><mi mathvariant="bold">′</mi><mi>𝐁</mi><mi>𝐌</mi></mrow><mo>=</mo><mi>𝚲</mi></mrow><annotation encoding="application/x-tex">\mathbf{M'BM}= \mathbf{\Lambda}</annotation></semantics></math>
and
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mrow><mi>𝐌</mi><mi mathvariant="bold">′</mi><mi>𝐖</mi><mi>𝐌</mi></mrow><mo>=</mo><mi>𝐈</mi></mrow><annotation encoding="application/x-tex">\mathbf{M'WM}= \mathbf{I}</annotation></semantics></math>.</p>
<p>Since the matrix
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>𝐖</mi><mrow><mi>−</mi><mfrac><mn>1</mn><mn>2</mn></mfrac></mrow></msup><mi>𝐁</mi><msup><mi>𝐖</mi><mrow><mi>−</mi><mfrac><mn>1</mn><mn>2</mn></mfrac></mrow></msup></mrow><annotation encoding="application/x-tex">\mathbf{W}^{-\frac{1}{2}} \mathbf{B} \mathbf{W}^{-\frac{1}{2}}</annotation></semantics></math>
is symmetric and positive semi-definite the eigenvalues in the matrix
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>𝚲</mi><annotation encoding="application/x-tex">\mathbf{\Lambda}</annotation></semantics></math>
are positive and ordered. The rank of
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>𝐁</mi><mo>=</mo><mi>m</mi><mi>i</mi><mi>n</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>p</mi><mo>,</mo><mi>G</mi><mo>−</mo><mn>1</mn><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">\mathbf{B} = min(p, G-1)</annotation></semantics></math>
so that only the first
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>r</mi><mi>a</mi><mi>n</mi><mi>k</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>𝐁</mi><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">rank(\mathbf{B})</annotation></semantics></math>
eigenvalues are non-zero. We form the canonical variates with the
transformation</p>
<p><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mover><mi>𝐘</mi><mo accent="true">‾</mo></mover><mo>=</mo><mover><mi>𝐗</mi><mo accent="true">‾</mo></mover><mi>𝐌</mi><mi>.</mi></mrow><annotation encoding="application/x-tex">
\bar{\mathbf{Y}} = \bar{\mathbf{X}}\mathbf{M}.
</annotation></semantics></math></p>
<p>To construct a 2D biplot, we plot the first two canonical variates
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mover><mi>𝐙</mi><mo accent="true">‾</mo></mover><mo>=</mo><mover><mi>𝐗</mi><mo accent="true">‾</mo></mover><msub><mrow><mi>𝐌</mi><mi>𝐉</mi></mrow><mn>2</mn></msub></mrow><annotation encoding="application/x-tex">\bar{\mathbf{Z}} = \bar{\mathbf{X}}\mathbf{MJ}_2</annotation></semantics></math>
where
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>𝐉</mi><mn>2</mn></msub><mi>′</mi><mo>=</mo><mrow><mo stretchy="true" form="prefix">[</mo><mtable><mtr><mtd columnalign="center" style="text-align: center"><msub><mi>𝐈</mi><mn>2</mn></msub></mtd><mtd columnalign="center" style="text-align: center"><mn>𝟎</mn></mtd></mtr></mtable><mo stretchy="true" form="postfix">]</mo></mrow></mrow><annotation encoding="application/x-tex">\mathbf{J}_2' = \begin{bmatrix} \mathbf{I}_2 &amp; \mathbf{0} \end{bmatrix}</annotation></semantics></math>.
We add the individual sample points with the same transformation</p>
<p><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>𝐙</mi><mo>=</mo><mi>𝐗</mi><msub><mrow><mi>𝐌</mi><mi>𝐉</mi></mrow><mn>2</mn></msub></mrow><annotation encoding="application/x-tex">
\mathbf{Z} = \mathbf{X}\mathbf{MJ}_2
</annotation></semantics></math> where
<math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>𝐉</mi><mn>2</mn></msub><mo>=</mo><mrow><mo stretchy="true" form="prefix">[</mo><mtable><mtr><mtd columnalign="center" style="text-align: center"><msub><mi>𝐈</mi><mn>2</mn></msub></mtd></mtr><mtr><mtd columnalign="center" style="text-align: center"><mn>𝟎</mn></mtd></mtr></mtable><mo stretchy="true" form="postfix">]</mo></mrow><mi>.</mi></mrow><annotation encoding="application/x-tex">
\mathbf{J}_2 = \begin{bmatrix}
                \mathbf{I}_2\\
                \mathbf{0}
               \end{bmatrix}.
</annotation></semantics></math> Interpolation of a new sample
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>𝐱</mi><mo>*</mo></msup><mo>:</mo><mi>p</mi><mo>×</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">\mathbf{x}^*:p \times 1</annotation></semantics></math>
follows as
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>𝐳</mi><mo>*</mo></msup><mi>′</mi><mo>:</mo><mn>2</mn><mo>×</mo><mn>1</mn><mo>=</mo><msup><mi>𝐱</mi><mo>*</mo></msup><mi>′</mi><msub><mrow><mi>𝐌</mi><mi>𝐉</mi></mrow><mn>2</mn></msub></mrow><annotation encoding="application/x-tex">{\mathbf{z}^*}':2 \times 1 ={\mathbf{x}^*}' \mathbf{MJ}_2</annotation></semantics></math>.
Using the inverse transformation
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>𝐱</mi><mi>′</mi><mo>=</mo><mi>𝐲</mi><mi>′</mi><msup><mi>𝐌</mi><mrow><mi>−</mi><mn>1</mn></mrow></msup></mrow><annotation encoding="application/x-tex">\mathbf{x}' = \mathbf{y}'\mathbf{M}^{-1}</annotation></semantics></math>,
all the points that will predict
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>μ</mi><annotation encoding="application/x-tex">\mu</annotation></semantics></math>
for variable
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>j</mi><annotation encoding="application/x-tex">j</annotation></semantics></math>
will have the form</p>
<p><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>μ</mi><mo>=</mo><mi>𝐲</mi><mi>′</mi><msup><mi>𝐌</mi><mrow><mi>−</mi><mn>1</mn></mrow></msup><msub><mi>𝐞</mi><mi>j</mi></msub></mrow><annotation encoding="application/x-tex">
\mu = \mathbf{y}'\mathbf{M}^{-1} \mathbf{e}_j
</annotation></semantics></math></p>
<p>where
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>𝐞</mi><mi>j</mi></msub><annotation encoding="application/x-tex">\mathbf{e}_j</annotation></semantics></math>
is a vector of zeros with a one in position
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>j</mi><annotation encoding="application/x-tex">j</annotation></semantics></math>.
All the points in the 2D biplot that predict the value
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>μ</mi><annotation encoding="application/x-tex">\mu</annotation></semantics></math>
will have</p>
<p><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>μ</mi><mo>=</mo><mrow><mo stretchy="true" form="prefix">[</mo><mtable><mtr><mtd columnalign="center" style="text-align: center"><msub><mi>z</mi><mn>1</mn></msub></mtd><mtd columnalign="center" style="text-align: center"><msub><mi>z</mi><mn>2</mn></msub></mtd><mtd columnalign="center" style="text-align: center"><mn>0</mn></mtd><mtd columnalign="center" style="text-align: center"><mi>…</mi></mtd><mtd columnalign="center" style="text-align: center"><mn>0</mn></mtd></mtr></mtable><mo stretchy="true" form="postfix">]</mo></mrow><msup><mi>𝐌</mi><mrow><mi>−</mi><mn>1</mn></mrow></msup><msub><mi>𝐞</mi><mi>j</mi></msub></mrow><annotation encoding="application/x-tex">
\mu = \begin{bmatrix} z_1 &amp; z_2 &amp; 0 &amp; \dots &amp; 0\end{bmatrix}\mathbf{M}^{-1} \mathbf{e}_j
</annotation></semantics></math></p>
<p>defining the prediction line as</p>
<p><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>μ</mi><mo>=</mo><msub><mi>𝐳</mi><mi>μ</mi></msub><mi>′</mi><msub><mi>𝐉</mi><mn>2</mn></msub><msup><mi>𝐌</mi><mrow><mi>−</mi><mn>1</mn></mrow></msup><msub><mi>𝐞</mi><mi>j</mi></msub><mi>.</mi></mrow><annotation encoding="application/x-tex">
\mu = \mathbf{z}_{\mu}' \mathbf{J}_2 \mathbf{M}^{-1} \mathbf{e}_j.
</annotation></semantics></math></p>
<p>Writing
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>𝐡</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>j</mi><mo stretchy="true" form="postfix">)</mo></mrow></msub><mo>=</mo><msub><mi>𝐉</mi><mn>2</mn></msub><msup><mi>𝐌</mi><mrow><mi>−</mi><mn>1</mn></mrow></msup><msub><mi>𝐞</mi><mi>j</mi></msub></mrow><annotation encoding="application/x-tex">\mathbf{h}_{(j)} = \mathbf{J}_2 \mathbf{M}^{-1} \mathbf{e}_j</annotation></semantics></math>
the construction of biplot axes is similar to the discussion in the
biplotEZ vignette for PCA biplots. The direction of the axis is given by
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>𝐡</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>j</mi><mo stretchy="true" form="postfix">)</mo></mrow></msub><annotation encoding="application/x-tex">\mathbf{h}_{(j)}</annotation></semantics></math>.
To find the intersection of the prediction line with
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>𝐡</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>j</mi><mo stretchy="true" form="postfix">)</mo></mrow></msub><annotation encoding="application/x-tex">\mathbf{h}_{(j)}</annotation></semantics></math>
we note that
<math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>𝐳</mi><msub><mi>′</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>μ</mi><mo stretchy="true" form="postfix">)</mo></mrow></msub><msub><mi>𝐡</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>j</mi><mo stretchy="true" form="postfix">)</mo></mrow></msub><mo>=</mo><mo stretchy="false" form="postfix">∥</mo><msub><mi>𝐳</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>μ</mi><mo stretchy="true" form="postfix">)</mo></mrow></msub><msup><mo stretchy="false" form="postfix">∥</mo><mn>2</mn></msup><mo stretchy="false" form="postfix">∥</mo><msub><mi>𝐡</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>j</mi><mo stretchy="true" form="postfix">)</mo></mrow></msub><msup><mo stretchy="false" form="postfix">∥</mo><mn>2</mn></msup><mi>c</mi><mi>o</mi><mi>s</mi><mrow><mo stretchy="true" form="prefix">(</mo><msub><mi>𝐳</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>μ</mi><mo stretchy="true" form="postfix">)</mo></mrow></msub><mo>,</mo><msub><mi>𝐡</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>j</mi><mo stretchy="true" form="postfix">)</mo></mrow></msub><mo stretchy="true" form="postfix">)</mo></mrow><mo>=</mo><mo stretchy="false" form="postfix">∥</mo><mi>𝐩</mi><msup><mo stretchy="false" form="postfix">∥</mo><mn>2</mn></msup><mo stretchy="false" form="postfix">∥</mo><msub><mi>𝐡</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>j</mi><mo stretchy="true" form="postfix">)</mo></mrow></msub><msup><mo stretchy="false" form="postfix">∥</mo><mn>2</mn></msup></mrow><annotation encoding="application/x-tex">
\mathbf{z}'_{(\mu)}\mathbf{h}_{(j)} = \| \mathbf{z}_{(\mu)} \|^2 \| \mathbf{h}_{(j)} \|^2 cos(\mathbf{z}_{(\mu)},\mathbf{h}_{(j)}) = 
\| \mathbf{p} \|^2 \| \mathbf{h}_{(j)} \|^2 
</annotation></semantics></math> where
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>𝐩</mi><annotation encoding="application/x-tex">\mathbf{p}</annotation></semantics></math>
is the length of the orthogonal projection of
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>𝐳</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>μ</mi><mo stretchy="true" form="postfix">)</mo></mrow></msub><annotation encoding="application/x-tex">\mathbf{z}_{(\mu)}</annotation></semantics></math>
on
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>𝐡</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>j</mi><mo stretchy="true" form="postfix">)</mo></mrow></msub><annotation encoding="application/x-tex">\mathbf{h}_{(j)}</annotation></semantics></math>.</p>
<p>Since
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>𝐩</mi><annotation encoding="application/x-tex">\mathbf{p}</annotation></semantics></math>
is along
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>𝐡</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>j</mi><mo stretchy="true" form="postfix">)</mo></mrow></msub><annotation encoding="application/x-tex">\mathbf{h}_{(j)}</annotation></semantics></math>
we can write
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>𝐩</mi><mo>=</mo><mi>c</mi><msub><mi>𝐡</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>j</mi><mo stretchy="true" form="postfix">)</mo></mrow></msub></mrow><annotation encoding="application/x-tex">\mathbf{p} = c\mathbf{h}_{(j)}</annotation></semantics></math>
and all points on the prediction line
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>μ</mi><mo>=</mo><mi>𝐳</mi><msub><mi>′</mi><mi>μ</mi></msub><msub><mi>𝐡</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>j</mi><mo stretchy="true" form="postfix">)</mo></mrow></msub></mrow><annotation encoding="application/x-tex">\mu = \mathbf{z}'_{\mu}\mathbf{h}_{(j)}</annotation></semantics></math>
project on the same point
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>c</mi><mi>μ</mi></msub><msub><mi>𝐡</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>j</mi><mo stretchy="true" form="postfix">)</mo></mrow></msub></mrow><annotation encoding="application/x-tex">c_{\mu}\mathbf{h}_{(j)}</annotation></semantics></math>.
We solve for
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>c</mi><mi>μ</mi></msub><annotation encoding="application/x-tex">c_{\mu}</annotation></semantics></math>
from
<math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>μ</mi><mo>=</mo><mi>𝐳</mi><msub><mi>′</mi><mi>μ</mi></msub><msub><mi>𝐡</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>j</mi><mo stretchy="true" form="postfix">)</mo></mrow></msub><mo>=</mo><mo stretchy="false" form="postfix">∥</mo><mi>𝐩</mi><msup><mo stretchy="false" form="postfix">∥</mo><mn>2</mn></msup><mo stretchy="false" form="postfix">∥</mo><msub><mi>𝐡</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>j</mi><mo stretchy="true" form="postfix">)</mo></mrow></msub><msup><mo stretchy="false" form="postfix">∥</mo><mn>2</mn></msup><mo>=</mo><mo stretchy="false" form="postfix">∥</mo><msub><mi>c</mi><mi>μ</mi></msub><msub><mi>𝐡</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>j</mi><mo stretchy="true" form="postfix">)</mo></mrow></msub><msup><mo stretchy="false" form="postfix">∥</mo><mn>2</mn></msup><mo stretchy="false" form="postfix">∥</mo><msub><mi>𝐡</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>j</mi><mo stretchy="true" form="postfix">)</mo></mrow></msub><msup><mo stretchy="false" form="postfix">∥</mo><mn>2</mn></msup></mrow><annotation encoding="application/x-tex">
\mu = \mathbf{z}'_{\mu}\mathbf{h}_{(j)}=\| \mathbf{p} \|^2 \| \mathbf{h}_{(j)} \|^2 = 
\| c_{\mu}\mathbf{h}_{(j)} \|^2 \| \mathbf{h}_{(j)} \|^2 
</annotation></semantics></math></p>
<p><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>c</mi><mi>μ</mi></msub><mo>=</mo><mfrac><mi>μ</mi><mrow><msub><mi>𝐡</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>j</mi><mo stretchy="true" form="postfix">)</mo></mrow></msub><mi>′</mi><msub><mi>𝐡</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>j</mi><mo stretchy="true" form="postfix">)</mo></mrow></msub></mrow></mfrac><mi>.</mi></mrow><annotation encoding="application/x-tex">
c_{\mu} = \frac{\mu}{\mathbf{h}_{(j)}'\mathbf{h}_{(j)}}.
</annotation></semantics></math> If we select ‘nice’ scale markers
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>τ</mi><mn>1</mn></msub><mo>,</mo><msub><mi>τ</mi><mn>2</mn></msub><mo>,</mo><mi>⋯</mi><msub><mi>τ</mi><mi>k</mi></msub></mrow><annotation encoding="application/x-tex">\tau_{1}, \tau_{2}, \cdots \tau_{k}</annotation></semantics></math>
for variable
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>j</mi><annotation encoding="application/x-tex">j</annotation></semantics></math>,
then
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>τ</mi><mi>h</mi></msub><mo>−</mo><msub><mover><mi>x</mi><mo accent="true">‾</mo></mover><mi>j</mi></msub><mo>=</mo><msub><mi>μ</mi><mi>h</mi></msub></mrow><annotation encoding="application/x-tex">\tau_{h}-\bar{x}_j = \mu_{h}</annotation></semantics></math>
and positions of these scale markers on
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>𝐡</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>j</mi><mo stretchy="true" form="postfix">)</mo></mrow></msub><annotation encoding="application/x-tex">\mathbf{h}_{(j)}</annotation></semantics></math>
are given by
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>p</mi><msub><mi>μ</mi><mn>1</mn></msub></msub><mo>,</mo><msub><mi>p</mi><msub><mi>μ</mi><mn>2</mn></msub></msub><mo>,</mo><mi>⋯</mi><msub><mi>p</mi><msub><mi>μ</mi><mi>k</mi></msub></msub></mrow><annotation encoding="application/x-tex">p_{\mu_{1}}, p_{\mu_{2}}, \cdots p_{\mu_{k}}</annotation></semantics></math>
with
<math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>p</mi><msub><mi>μ</mi><mi>h</mi></msub></msub><mo>=</mo><msub><mi>c</mi><msub><mi>μ</mi><mi>h</mi></msub></msub><msub><mi>𝐡</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>j</mi><mo stretchy="true" form="postfix">)</mo></mrow></msub><mo>=</mo><mfrac><msub><mi>μ</mi><mi>h</mi></msub><mrow><msub><mi>𝐡</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>j</mi><mo stretchy="true" form="postfix">)</mo></mrow></msub><mi>′</mi><msub><mi>𝐡</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>j</mi><mo stretchy="true" form="postfix">)</mo></mrow></msub></mrow></mfrac><msub><mi>𝐡</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>j</mi><mo stretchy="true" form="postfix">)</mo></mrow></msub></mrow><annotation encoding="application/x-tex">
p_{\mu_h} = c_{\mu_h}\mathbf{h}_{(j)} =  \frac{\mu_h}{\mathbf{h}_{(j)}'\mathbf{h}_{(j)}}\mathbf{h}_{(j)}
</annotation></semantics></math></p>
<p><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo>=</mo><mfrac><msub><mi>μ</mi><mi>h</mi></msub><mrow><msub><mi>𝐞</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>j</mi><mo stretchy="true" form="postfix">)</mo></mrow></msub><mi>′</mi><msup><mrow><mi>𝐌</mi><mi mathvariant="bold">′</mi></mrow><mrow><mi>−</mi><mn>1</mn></mrow></msup><mi>𝐉</mi><msup><mi>𝐌</mi><mrow><mi>−</mi><mn>1</mn></mrow></msup><msub><mi>𝐞</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>j</mi><mo stretchy="true" form="postfix">)</mo></mrow></msub></mrow></mfrac><mspace width="0.222em"></mspace><msub><mi>𝐉</mi><mn>2</mn></msub><msup><mi>𝐌</mi><mrow><mi>−</mi><mn>1</mn></mrow></msup><msub><mi>𝐞</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>j</mi><mo stretchy="true" form="postfix">)</mo></mrow></msub></mrow><annotation encoding="application/x-tex">
= \frac{\mu_h}{\mathbf{e}_{(j)}' \mathbf{M'}^{-1} \mathbf{J} \mathbf{M}^{-1} \mathbf{e}_{(j)}}\ \mathbf{J}_2 \mathbf{M}^{-1} \mathbf{e}_{(j)}
</annotation></semantics></math></p>
<p>with
<math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>𝐉</mi><mo>=</mo><mrow><mo stretchy="true" form="prefix">[</mo><mtable><mtr><mtd columnalign="center" style="text-align: center"><msub><mi>𝐈</mi><mn>2</mn></msub></mtd><mtd columnalign="center" style="text-align: center"><mn>𝟎</mn></mtd></mtr><mtr><mtd columnalign="center" style="text-align: center"><mn>𝟎</mn></mtd><mtd columnalign="center" style="text-align: center"><mn>𝟎</mn></mtd></mtr></mtable><mo stretchy="true" form="postfix">]</mo></mrow><mi>.</mi></mrow><annotation encoding="application/x-tex">
\mathbf{J} = \begin{bmatrix}
              \mathbf{I}_2 &amp; \mathbf{0}\\
              \mathbf{0} &amp; \mathbf{0}
             \end{bmatrix}.
</annotation></semantics></math></p>
</div>
<div class="section level2">
<h2 id="the-function-cva">The function <code>CVA()</code><a class="anchor" aria-label="anchor" href="#the-function-cva"></a>
</h2>
<p>To obtain a CVA biplot of the <code>state.x77</code> data set,
optimally separating the classes according to <code>state.region</code>
we call</p>
<div class="sourceCode" id="cb2"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="../reference/biplot.html">biplot</a></span><span class="op">(</span><span class="va">state.x77</span><span class="op">)</span> <span class="op">|&gt;</span> </span>
<span>  <span class="fu"><a href="../reference/CVA.html">CVA</a></span><span class="op">(</span>classes <span class="op">=</span> <span class="va">state.region</span><span class="op">)</span> <span class="op">|&gt;</span> </span>
<span>  <span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html" class="external-link">plot</a></span><span class="op">(</span><span class="op">)</span></span></code></pre></div>
<p><img src="Class_separation_files/figure-html/unnamed-chunk-2-1.png" width="672"></p>
<p>Fitting
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>α</mi><annotation encoding="application/x-tex">\alpha</annotation></semantics></math>-bags
to the classes makes it easier to compare class overlap and separation.
For a detailed discussion on
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>α</mi><annotation encoding="application/x-tex">\alpha</annotation></semantics></math>-bags,
see the <em>biplotEZ</em> vignette.</p>
<div class="sourceCode" id="cb3"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="../reference/biplot.html">biplot</a></span><span class="op">(</span><span class="va">state.x77</span><span class="op">)</span> <span class="op">|&gt;</span> <span class="fu"><a href="../reference/CVA.html">CVA</a></span><span class="op">(</span>classes <span class="op">=</span> <span class="va">state.region</span><span class="op">)</span> <span class="op">|&gt;</span> <span class="fu"><a href="../reference/alpha.bags.html">alpha.bags</a></span><span class="op">(</span><span class="op">)</span> <span class="op">|&gt;</span> </span>
<span>  <span class="fu"><a href="../reference/legend.type.html">legend.type</a></span> <span class="op">(</span>bags <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span> <span class="op">|&gt;</span> </span>
<span>  <span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html" class="external-link">plot</a></span><span class="op">(</span><span class="op">)</span></span>
<span><span class="co">#&gt; Computing 0.95 -bag for Northeast </span></span>
<span><span class="co">#&gt; Computing 0.95 -bag for South </span></span>
<span><span class="co">#&gt; Computing 0.95 -bag for North Central </span></span>
<span><span class="co">#&gt; Computing 0.95 -bag for West</span></span></code></pre></div>
<p><img src="Class_separation_files/figure-html/unnamed-chunk-3-1.png" width="672"></p>
</div>
<div class="section level2">
<h2 id="the-function-means">The function <code>means()</code><a class="anchor" aria-label="anchor" href="#the-function-means"></a>
</h2>
<p>This function controls the aesthetics of the class means in the
biplot. The function accepts as first argument an object of class
<code>biplot</code> where the aesthetics should be applied. Let us first
construct a CVA biplot of the <code>state.x77</code> data with samples
optimally separated according to <code>state.division</code>.</p>
<div class="sourceCode" id="cb4"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="../reference/biplot.html">biplot</a></span><span class="op">(</span><span class="va">state.x77</span>, scaled <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span> <span class="op">|&gt;</span> </span>
<span>  <span class="fu"><a href="../reference/CVA.html">CVA</a></span><span class="op">(</span>classes <span class="op">=</span> <span class="va">state.division</span><span class="op">)</span> <span class="op">|&gt;</span> </span>
<span>  <span class="fu"><a href="../reference/legend.type.html">legend.type</a></span><span class="op">(</span>means <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span> <span class="op">|&gt;</span> </span>
<span>  <span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html" class="external-link">plot</a></span><span class="op">(</span><span class="op">)</span></span></code></pre></div>
<p><img src="Class_separation_files/figure-html/unnamed-chunk-4-1.png" width="672"></p>
<p>Instead of adding a legend, we can choose to label the class means.
Furthermore, the colour of each class mean defaults to the colour of the
samples. We wish to select a different colour and plotting character for
the class means.</p>
<div class="sourceCode" id="cb5"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="../reference/biplot.html">biplot</a></span><span class="op">(</span><span class="va">state.x77</span>, scaled <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span> <span class="op">|&gt;</span> </span>
<span>  <span class="fu"><a href="../reference/CVA.html">CVA</a></span><span class="op">(</span>classes <span class="op">=</span> <span class="va">state.division</span><span class="op">)</span> <span class="op">|&gt;</span> </span>
<span>  <span class="fu"><a href="../reference/means.html">means</a></span><span class="op">(</span>label <span class="op">=</span> <span class="cn">TRUE</span>, col <span class="op">=</span> <span class="st">"olivedrab"</span>, pch <span class="op">=</span> <span class="fl">15</span><span class="op">)</span> <span class="op">|&gt;</span> </span>
<span>  <span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html" class="external-link">plot</a></span><span class="op">(</span><span class="op">)</span></span></code></pre></div>
<p><img src="Class_separation_files/figure-html/unnamed-chunk-5-1.png" width="672"></p>
<p>If we choose to only show the class means for the central states, the
argument <code>which</code> is used either indicating the number(s) in
the sequence of levels (<code>which = 4:7</code>), or as shown below,
the levels themselves:</p>
<div class="sourceCode" id="cb6"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="../reference/biplot.html">biplot</a></span><span class="op">(</span><span class="va">state.x77</span>, scaled <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span> <span class="op">|&gt;</span> </span>
<span>  <span class="fu"><a href="../reference/CVA.html">CVA</a></span><span class="op">(</span>classes <span class="op">=</span> <span class="va">state.division</span><span class="op">)</span> <span class="op">|&gt;</span> </span>
<span>  <span class="fu"><a href="../reference/means.html">means</a></span> <span class="op">(</span>which <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="st">"West North Central"</span>, <span class="st">"West South Central"</span>, <span class="st">"East South Central"</span>, </span>
<span>                     <span class="st">"East North Central"</span><span class="op">)</span>, label <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span> <span class="op">|&gt;</span></span>
<span>  <span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html" class="external-link">plot</a></span><span class="op">(</span><span class="op">)</span></span></code></pre></div>
<p><img src="Class_separation_files/figure-html/unnamed-chunk-6-1.png" width="672"></p>
<p>The size of the labels is controlled with <code>label.cex</code>
which can be specified either as a single value (for all class means) or
a vector indicating size values for each individual sample. The colour
of the labels defaults to the colour(s) of the class means. However,
individual label colours can be spesified with <code>label.col</code>,
similar to <code>label.cex</code> as either a single value of a vector
of length equal to the number of classes.</p>
<div class="sourceCode" id="cb7"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="../reference/biplot.html">biplot</a></span><span class="op">(</span><span class="va">state.x77</span>, scaled <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span> <span class="op">|&gt;</span> </span>
<span>  <span class="fu"><a href="../reference/CVA.html">CVA</a></span><span class="op">(</span>classes <span class="op">=</span> <span class="va">state.division</span><span class="op">)</span> <span class="op">|&gt;</span> </span>
<span>  <span class="fu"><a href="../reference/means.html">means</a></span> <span class="op">(</span>col <span class="op">=</span> <span class="st">"olivedrab"</span>, pch <span class="op">=</span> <span class="fl">15</span>, cex <span class="op">=</span> <span class="fl">1.5</span>,</span>
<span>         label <span class="op">=</span> <span class="cn">TRUE</span>, label.col <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="st">"blue"</span>,<span class="st">"green"</span>,<span class="st">"gold"</span>,<span class="st">"cyan"</span>,<span class="st">"magenta"</span>,</span>
<span>                                     <span class="st">"black"</span>,<span class="st">"red"</span>,<span class="st">"grey"</span>,<span class="st">"purple"</span><span class="op">)</span><span class="op">)</span> <span class="op">|&gt;</span></span>
<span>  <span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html" class="external-link">plot</a></span><span class="op">(</span><span class="op">)</span></span></code></pre></div>
<p><img src="Class_separation_files/figure-html/unnamed-chunk-7-1.png" width="672"></p>
<p>We can also make use of the functionality of the <code>ggrepel</code>
package to place the labels.</p>
<div class="sourceCode" id="cb8"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="../reference/biplot.html">biplot</a></span><span class="op">(</span><span class="va">state.x77</span>, scaled <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span> <span class="op">|&gt;</span> </span>
<span>  <span class="fu"><a href="../reference/CVA.html">CVA</a></span><span class="op">(</span>classes <span class="op">=</span> <span class="va">state.division</span><span class="op">)</span> <span class="op">|&gt;</span> </span>
<span>  <span class="fu"><a href="../reference/samples.html">samples</a></span> <span class="op">(</span>label <span class="op">=</span> <span class="st">"ggrepel"</span>, label.cex<span class="op">=</span><span class="fl">0.65</span><span class="op">)</span> <span class="op">|&gt;</span> </span>
<span>  <span class="fu"><a href="../reference/means.html">means</a></span> <span class="op">(</span>label <span class="op">=</span> <span class="st">"ggrepel"</span>, label.cex<span class="op">=</span><span class="fl">0.8</span><span class="op">)</span> <span class="op">|&gt;</span> <span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html" class="external-link">plot</a></span><span class="op">(</span><span class="op">)</span></span></code></pre></div>
<p><img src="Class_separation_files/figure-html/unnamed-chunk-8-1.png" width="672"></p>
</div>
<div class="section level2">
<h2 id="the-function-classify">The function <code>classify()</code><a class="anchor" aria-label="anchor" href="#the-function-classify"></a>
</h2>
<p>Classification regions can be added to the CVA biplot with the
function <code><a href="../reference/classify.html">classify()</a></code>. The argument
<code>classify.regions</code> must be set equal to <code>TRUE</code> to
render the regions in the plot. Other arguments such as
<code>col</code>, <code>opacity</code> and <code>borders</code> allows
to change the aesthetics of the regions.</p>
<div class="sourceCode" id="cb9"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="../reference/biplot.html">biplot</a></span><span class="op">(</span><span class="va">state.x77</span>, scaled <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span> <span class="op">|&gt;</span> </span>
<span>  <span class="fu"><a href="../reference/CVA.html">CVA</a></span><span class="op">(</span>classes <span class="op">=</span> <span class="va">state.division</span><span class="op">)</span> <span class="op">|&gt;</span></span>
<span>  <span class="fu"><a href="../reference/classify.html">classify</a></span><span class="op">(</span>classify.regions <span class="op">=</span> <span class="cn">TRUE</span>,opacity <span class="op">=</span> <span class="fl">0.2</span><span class="op">)</span> <span class="op">|&gt;</span> </span>
<span>  <span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html" class="external-link">plot</a></span><span class="op">(</span><span class="op">)</span></span></code></pre></div>
<p><img src="Class_separation_files/figure-html/unnamed-chunk-9-1.png" width="672"></p>
</div>
<div class="section level2">
<h2 id="the-functions-fit-measures-and-summary">The functions <code>fit.measures()</code> and
<code>summary()</code><a class="anchor" aria-label="anchor" href="#the-functions-fit-measures-and-summary"></a>
</h2>
<p>There is a number of fit measures that are specific to CVA biplots.
The measures are computed with the function <code><a href="../reference/fit.measures.html">fit.measures()</a></code>
and the results are displayed by the function
<code><a href="https://rdrr.io/r/base/summary.html" class="external-link">summary()</a></code>.</p>
<p>Canonical variate analysis can be considered as a transformation of
the original variables to the canonical space followed by constructing a
PCA biplot of canonical variables. The matrix of class means
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mover><mi>𝐗</mi><mo accent="true">‾</mo></mover><mo>=</mo><msup><mrow><mo stretchy="true" form="prefix">(</mo><mrow><mi>𝐆</mi><mi mathvariant="bold">′</mi><mi>𝐆</mi></mrow><mo stretchy="true" form="postfix">)</mo></mrow><mrow><mi>−</mi><mn>1</mn></mrow></msup><mrow><mi>𝐆</mi><mi mathvariant="bold">′</mi><mi>𝐗</mi></mrow></mrow><annotation encoding="application/x-tex">\bar{\mathbf{X}} = (\mathbf{G'G})^{-1} \mathbf{G'X}</annotation></semantics></math>
is transformed to
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mover><mi>𝐗</mi><mo accent="true">‾</mo></mover><mi>𝐋</mi></mrow><annotation encoding="application/x-tex">\mathbf{\bar{X}L}</annotation></semantics></math>
where
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>𝐋</mi><annotation encoding="application/x-tex">\mathbf{L}</annotation></semantics></math>
is a non-singular matrix such that
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msup><mrow><mi>𝐋</mi><mi>𝐋</mi><mi mathvariant="bold">′</mi><mo mathvariant="bold">=</mo><mi>𝐖</mi></mrow><mrow><mi>−</mi><mn>1</mn></mrow></msup><annotation encoding="application/x-tex">\mathbf{LL'=W}^{-1}</annotation></semantics></math>.
Pricipal component analysis finds the orthogonal matrix
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>𝐕</mi><annotation encoding="application/x-tex">\mathbf{V}</annotation></semantics></math>
such that</p>
<p><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mrow><mo stretchy="true" form="prefix" mathvariant="bold">(</mo><mi>𝐋</mi><mi mathvariant="bold">′</mi><mover><mi>𝐗</mi><mo accent="true">‾</mo></mover><mi mathvariant="bold">′</mi><mi>𝐂</mi><mover><mi>𝐗</mi><mo accent="true">‾</mo></mover><mi>𝐋</mi><mo stretchy="true" form="postfix" mathvariant="bold">)</mo></mrow><mi>𝐕</mi><mo mathvariant="bold">=</mo><mi>𝐕</mi><mi>𝚲</mi></mrow><annotation encoding="application/x-tex">
\mathbf{(L'\bar{X}'C\bar{X}L)V=V \Lambda}
</annotation></semantics></math></p>
<p>where
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>𝐌</mi><mo mathvariant="bold">=</mo><mi>𝐋</mi><mi>𝐕</mi></mrow><annotation encoding="application/x-tex">\mathbf{M = LV}</annotation></semantics></math>
as defined in section 1. The predicted values for the class means is
given by</p>
<p><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mover><mover><mi>𝐗</mi><mo accent="true">‾</mo></mover><mo accent="true">̂</mo></mover><mo>=</mo><mrow><mover><mi>𝐗</mi><mo accent="true">‾</mo></mover><mi>𝐌</mi><mi>𝐉</mi></mrow><msup><mi>𝐌</mi><mrow><mi>−</mi><mn>1</mn></mrow></msup><mi>.</mi></mrow><annotation encoding="application/x-tex">
\mathbf{\hat{\bar{X}}} = \mathbf{\bar{X}MJ}\mathbf{M}^{-1}.
</annotation></semantics></math></p>
<div class="section level3">
<h3 id="overall-quality-of-fit">Overall quality of fit<a class="anchor" aria-label="anchor" href="#overall-quality-of-fit"></a>
</h3>
<p>Based on the two-step process described above, there are two measures
of quality of fit. The quality of the approximation of the canonical
variables
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mover><mi>𝐗</mi><mo accent="true">‾</mo></mover><mi>𝐋</mi></mrow><annotation encoding="application/x-tex">\mathbf{\bar{X}L}</annotation></semantics></math>
in the
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mn>2</mn><annotation encoding="application/x-tex">2</annotation></semantics></math>-dimensional
display is given by</p>
<p><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>Q</mi><mi>u</mi><mi>a</mi><mi>l</mi><mi>i</mi><mi>t</mi><mi>y</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>c</mi><mi>a</mi><mi>n</mi><mi>o</mi><mi>n</mi><mi>i</mi><mi>c</mi><mi>a</mi><mi>l</mi><mspace width="0.222em"></mspace><mi>v</mi><mi>a</mi><mi>r</mi><mi>i</mi><mi>a</mi><mi>b</mi><mi>l</mi><mi>e</mi><mi>s</mi><mo stretchy="true" form="postfix">)</mo></mrow><mo>=</mo><mfrac><mrow><mi>t</mi><mi>r</mi><mrow><mo stretchy="true" form="prefix">(</mo><mrow><mi>𝚲</mi><mi>𝐉</mi></mrow><mo stretchy="true" form="postfix">)</mo></mrow></mrow><mrow><mi>t</mi><mi>r</mi><mo stretchy="false" form="prefix">(</mo><mrow><mi>𝚲</mi><mo stretchy="false" form="postfix" mathvariant="bold">)</mo></mrow></mrow></mfrac></mrow><annotation encoding="application/x-tex">
Quality (canonical \: variables) = \frac{tr(\mathbf{\Lambda J})}{tr(\mathbf{\Lambda)}}
</annotation></semantics></math> and the quality of the approximation of
the original variables
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mover><mi>𝐗</mi><mo accent="true">‾</mo></mover><annotation encoding="application/x-tex">\mathbf{\bar{X}}</annotation></semantics></math>
in the 2D CVA biplot is given by</p>
<p><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>Q</mi><mi>u</mi><mi>a</mi><mi>l</mi><mi>i</mi><mi>t</mi><mi>y</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>o</mi><mi>r</mi><mi>i</mi><mi>g</mi><mi>i</mi><mi>n</mi><mi>a</mi><mi>l</mi><mspace width="0.222em"></mspace><mi>v</mi><mi>a</mi><mi>r</mi><mi>i</mi><mi>a</mi><mi>b</mi><mi>l</mi><mi>e</mi><mi>s</mi><mo stretchy="true" form="postfix">)</mo></mrow><mo>=</mo><mfrac><mrow><mi>t</mi><mi>r</mi><mrow><mo stretchy="true" form="prefix">(</mo><mrow><mi>𝚲</mi><mi>𝐉</mi></mrow><mo stretchy="true" form="postfix">)</mo></mrow></mrow><mrow><mi>t</mi><mi>r</mi><mo stretchy="false" form="prefix">(</mo><mrow><mi>𝚲</mi><mo stretchy="false" form="postfix" mathvariant="bold">)</mo></mrow></mrow></mfrac></mrow><annotation encoding="application/x-tex">
Quality (original \: variables) = \frac{tr(\mathbf{\Lambda J})}{tr(\mathbf{\Lambda)}}
</annotation></semantics></math></p>
</div>
<div class="section level3">
<h3 id="adequacy-of-representation-of-variables">Adequacy of representation of variables<a class="anchor" aria-label="anchor" href="#adequacy-of-representation-of-variables"></a>
</h3>
<p>The adequacy with which each of the variables is represented in the
biplot is given by the elementwise ratios</p>
<p><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>A</mi><mi>d</mi><mi>e</mi><mi>q</mi><mi>u</mi><mi>a</mi><mi>c</mi><mi>y</mi><mo>=</mo><mfrac><mrow><mi>d</mi><mi>i</mi><mi>a</mi><mi>g</mi><mrow><mo stretchy="true" form="prefix">(</mo><mrow><mi>𝐌</mi><mi>𝐉</mi><mi>𝐌</mi><mi mathvariant="bold">′</mi></mrow><mo stretchy="true" form="postfix">)</mo></mrow></mrow><mrow><mi>d</mi><mi>i</mi><mi>a</mi><mi>g</mi><mrow><mo stretchy="true" form="prefix">(</mo><mrow><mi>𝐌</mi><mi>𝐌</mi><mi mathvariant="bold">′</mi></mrow><mo stretchy="true" form="postfix">)</mo></mrow></mrow></mfrac><mi>.</mi></mrow><annotation encoding="application/x-tex">
Adequacy = \frac{diag(\mathbf{MJM'})}{diag(\mathbf{MM'})}.
</annotation></semantics></math></p>
</div>
<div class="section level3">
<h3 id="predictivity">Predictivity<a class="anchor" aria-label="anchor" href="#predictivity"></a>
</h3>
<div class="section level4">
<h4 id="between-class-predictivity">Between class predictivity<a class="anchor" aria-label="anchor" href="#between-class-predictivity"></a>
</h4>
<p>The axis and class mean predictivities are defined in terms of the
weighted class means.</p>
<div class="section level5">
<h5 id="axis-predictivity">Axis predictivity<a class="anchor" aria-label="anchor" href="#axis-predictivity"></a>
</h5>
<p>The elementwise ratios for the predictivity of each of the axes are
given by</p>
<p><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>a</mi><mi>x</mi><mi>i</mi><mi>s</mi><mspace width="0.222em"></mspace><mi>p</mi><mi>r</mi><mi>e</mi><mi>d</mi><mi>i</mi><mi>c</mi><mi>t</mi><mi>i</mi><mi>v</mi><mi>i</mi><mi>t</mi><mi>y</mi><mo>=</mo><mfrac><mrow><mi>d</mi><mi>i</mi><mi>a</mi><mi>g</mi><mrow><mo stretchy="true" form="prefix">(</mo><mover><mover><mi>𝐗</mi><mo accent="true">‾</mo></mover><mo accent="true">̂</mo></mover><mi>′</mi><mrow><mi>𝐂</mi><mover><mover><mi>𝐗</mi><mo accent="true">‾</mo></mover><mo accent="true">̂</mo></mover></mrow><mo stretchy="true" form="postfix">)</mo></mrow></mrow><mrow><mi>d</mi><mi>i</mi><mi>a</mi><mi>g</mi><mrow><mo stretchy="true" form="prefix">(</mo><mover><mi>𝐗</mi><mo accent="true">‾</mo></mover><mi>′</mi><mrow><mi>𝐂</mi><mover><mi>𝐗</mi><mo accent="true">‾</mo></mover></mrow><mo stretchy="true" form="postfix">)</mo></mrow></mrow></mfrac><mi>.</mi></mrow><annotation encoding="application/x-tex">
axis \: predictivity = \frac{diag(\mathbf{\hat{\bar{X}}}'\mathbf{C\hat{\bar{X}}})}{diag(\mathbf{\bar{X}}'\mathbf{C\bar{X}})}.
</annotation></semantics></math></p>
</div>
<div class="section level5">
<h5 id="class-predictivity">Class predictivity<a class="anchor" aria-label="anchor" href="#class-predictivity"></a>
</h5>
<p>Similarly for each of the class means the elementwise ratio is
computed from</p>
<p><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>c</mi><mi>l</mi><mi>a</mi><mi>s</mi><mi>s</mi><mspace width="0.222em"></mspace><mi>p</mi><mi>r</mi><mi>e</mi><mi>d</mi><mi>i</mi><mi>c</mi><mi>t</mi><mi>i</mi><mi>v</mi><mi>i</mi><mi>t</mi><mi>y</mi><mo>=</mo><mfrac><mrow><mi>d</mi><mi>i</mi><mi>a</mi><mi>g</mi><mrow><mo stretchy="true" form="prefix">(</mo><msup><mi>𝐂</mi><mfrac><mn>1</mn><mn>2</mn></mfrac></msup><mover><mover><mi>𝐗</mi><mo accent="true">‾</mo></mover><mo accent="true">̂</mo></mover><mi>′</mi><msup><mi>𝐖</mi><mrow><mi mathvariant="bold">−</mi><mn>𝟏</mn></mrow></msup><mover><mover><mi>𝐗</mi><mo accent="true">‾</mo></mover><mo accent="true">̂</mo></mover><msup><mi>𝐂</mi><mfrac><mn>1</mn><mn>2</mn></mfrac></msup><mo stretchy="true" form="postfix">)</mo></mrow></mrow><mrow><mi>d</mi><mi>i</mi><mi>a</mi><mi>g</mi><mrow><mo stretchy="true" form="prefix">(</mo><msup><mi>𝐂</mi><mfrac><mn>1</mn><mn>2</mn></mfrac></msup><mover><mi>𝐗</mi><mo accent="true">‾</mo></mover><mi>′</mi><msup><mi>𝐖</mi><mrow><mi mathvariant="bold">−</mi><mn>𝟏</mn></mrow></msup><mover><mi>𝐗</mi><mo accent="true">‾</mo></mover><msup><mi>𝐂</mi><mfrac><mn>1</mn><mn>2</mn></mfrac></msup><mo stretchy="true" form="postfix">)</mo></mrow></mrow></mfrac><mi>.</mi></mrow><annotation encoding="application/x-tex">
class \: predictivity = \frac{diag(\mathbf{C}^{\frac{1}{2}}\mathbf{\hat{\bar{X}}}'\mathbf{W^{-1}}\mathbf{\hat{\bar{X}}}\mathbf{C}^{\frac{1}{2}})}{diag(\mathbf{C}^{\frac{1}{2}}\mathbf{\bar{X}}'\mathbf{W^{-1}}\mathbf{\bar{X}}\mathbf{C}^{\frac{1}{2}})}.
</annotation></semantics></math></p>
</div>
</div>
<div class="section level4">
<h4 id="within-class-predictivity">Within class predictivity<a class="anchor" aria-label="anchor" href="#within-class-predictivity"></a>
</h4>
<p>We define the matrix of samples as deviations from their class means
as</p>
<p><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mrow><mo stretchy="true" form="prefix">(</mo><mrow><mi>𝐈</mi><mo mathvariant="bold">−</mo><mi>𝐇</mi></mrow><mo stretchy="true" form="postfix">)</mo></mrow><mi>𝐗</mi><mo>=</mo><mrow><mo stretchy="true" form="prefix">(</mo><msub><mi>𝐈</mi><mi>n</mi></msub><mo>−</mo><mi>𝐆</mi><msup><mrow><mo stretchy="true" form="prefix">(</mo><mrow><mi>𝐆</mi><mi mathvariant="bold">′</mi><mi>𝐆</mi></mrow><mo stretchy="true" form="postfix">)</mo></mrow><mrow><mi>−</mi><mn>1</mn></mrow></msup><mi>𝐆</mi><mi>′</mi><mo stretchy="true" form="postfix">)</mo></mrow><mi>𝐗</mi></mrow><annotation encoding="application/x-tex">
(\mathbf{I-H})\mathbf{X}=(\mathbf{I}_n-\mathbf{G}(\mathbf{G'G})^{-1}\mathbf{G}')\mathbf{X}
</annotation></semantics></math></p>
<p>where
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>𝐇</mi><mo>=</mo><mi>𝐆</mi><msup><mrow><mo stretchy="true" form="prefix">(</mo><mrow><mi>𝐆</mi><mi mathvariant="bold">′</mi><mi>𝐆</mi></mrow><mo stretchy="true" form="postfix">)</mo></mrow><mrow><mi>−</mi><mn>1</mn></mrow></msup><mi>𝐆</mi><mi>′</mi></mrow><annotation encoding="application/x-tex">\mathbf{H} = \mathbf{G}(\mathbf{G'G})^{-1}\mathbf{G}'</annotation></semantics></math>.</p>
<div class="section level5">
<h5 id="within-class-axis-predictivity">Within class axis predictivity<a class="anchor" aria-label="anchor" href="#within-class-axis-predictivity"></a>
</h5>
<p>The within class axis predictivity is computed as the elementwise
ratios</p>
<p><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>w</mi><mi>i</mi><mi>t</mi><mi>h</mi><mi>i</mi><mi>n</mi><mspace width="0.222em"></mspace><mi>c</mi><mi>l</mi><mi>a</mi><mi>s</mi><mi>s</mi><mspace width="0.222em"></mspace><mi>a</mi><mi>x</mi><mi>i</mi><mi>s</mi><mspace width="0.222em"></mspace><mi>p</mi><mi>r</mi><mi>e</mi><mi>d</mi><mi>i</mi><mi>c</mi><mi>t</mi><mi>i</mi><mi>v</mi><mi>i</mi><mi>t</mi><mi>y</mi><mo>=</mo><mfrac><mrow><mi>d</mi><mi>i</mi><mi>a</mi><mi>g</mi><mo stretchy="false" form="prefix">(</mo><mover><mi>𝐗</mi><mo accent="true">̂</mo></mover><mi>′</mi><mrow><mo stretchy="true" form="prefix">(</mo><mrow><mi>𝐈</mi><mo mathvariant="bold">−</mo><mi>𝐇</mi><mo stretchy="false" form="postfix" mathvariant="bold">)</mo><mover><mi>𝐗</mi><mo accent="true">̂</mo></mover></mrow><mo stretchy="true" form="postfix">)</mo></mrow></mrow><mrow><mi>d</mi><mi>i</mi><mi>a</mi><mi>g</mi><mo stretchy="false" form="prefix">(</mo><mi>𝐗</mi><mi>′</mi><mrow><mo stretchy="true" form="prefix">(</mo><mrow><mi>𝐈</mi><mo mathvariant="bold">−</mo><mi>𝐇</mi><mo stretchy="false" form="postfix" mathvariant="bold">)</mo><mi>𝐗</mi></mrow><mo stretchy="true" form="postfix">)</mo></mrow></mrow></mfrac><mi>.</mi></mrow><annotation encoding="application/x-tex">
within \: class \: axis \: predictivity = \frac{diag(\mathbf{\hat{X}}'(\mathbf{I-H)\hat{X}})}{diag(\mathbf{X}'(\mathbf{I-H)X})}.
</annotation></semantics></math></p>
</div>
<div class="section level5">
<h5 id="within-class-sample-predictivity">Within class sample predictivity<a class="anchor" aria-label="anchor" href="#within-class-sample-predictivity"></a>
</h5>
<p>Unlike PCA biplots, sample predictivity for CVA biplots are computed
for the observations expressed as deviations from their class means. The
elementwise ratios is obtained from</p>
<p><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>w</mi><mi>i</mi><mi>t</mi><mi>h</mi><mi>i</mi><mi>n</mi><mspace width="0.222em"></mspace><mi>c</mi><mi>l</mi><mi>a</mi><mi>s</mi><mi>s</mi><mspace width="0.222em"></mspace><mi>a</mi><mi>x</mi><mi>i</mi><mi>s</mi><mspace width="0.222em"></mspace><mi>p</mi><mi>r</mi><mi>e</mi><mi>d</mi><mi>i</mi><mi>c</mi><mi>t</mi><mi>i</mi><mi>v</mi><mi>i</mi><mi>t</mi><mi>y</mi><mo>=</mo><mfrac><mrow><mi>d</mi><mi>i</mi><mi>a</mi><mi>g</mi><mrow><mo stretchy="true" form="prefix">(</mo><mrow><mrow><mo stretchy="true" form="prefix" mathvariant="bold">(</mo><mi>𝐈</mi><mo mathvariant="bold">−</mo><mi>𝐇</mi><mo stretchy="true" form="postfix" mathvariant="bold">)</mo></mrow><mover><mi>𝐗</mi><mo accent="true">̂</mo></mover></mrow><msup><mi>𝐖</mi><mrow><mi>−</mi><mn>1</mn></mrow></msup><mrow><mover><mi>𝐗</mi><mo accent="true">̂</mo></mover><mi mathvariant="bold">′</mi><mrow><mo stretchy="true" form="prefix" mathvariant="bold">(</mo><mi>𝐈</mi><mo mathvariant="bold">−</mo><mi>𝐇</mi><mo stretchy="true" form="postfix" mathvariant="bold">)</mo></mrow></mrow><mo stretchy="true" form="postfix">)</mo></mrow></mrow><mrow><mi>d</mi><mi>i</mi><mi>a</mi><mi>g</mi><mrow><mo stretchy="true" form="prefix">(</mo><mrow><mrow><mo stretchy="true" form="prefix" mathvariant="bold">(</mo><mi>𝐈</mi><mo mathvariant="bold">−</mo><mi>𝐇</mi><mo stretchy="true" form="postfix" mathvariant="bold">)</mo></mrow><mi>𝐗</mi></mrow><msup><mi>𝐖</mi><mrow><mi>−</mi><mn>1</mn></mrow></msup><mrow><mi>𝐗</mi><mi mathvariant="bold">′</mi><mrow><mo stretchy="true" form="prefix" mathvariant="bold">(</mo><mi>𝐈</mi><mo mathvariant="bold">−</mo><mi>𝐇</mi><mo stretchy="true" form="postfix" mathvariant="bold">)</mo></mrow></mrow><mo stretchy="true" form="postfix">)</mo></mrow></mrow></mfrac><mi>.</mi></mrow><annotation encoding="application/x-tex">
within \: class \: axis \: predictivity = \frac{diag(\mathbf{(I-H)\hat{X}}\mathbf{W}^{-1}\mathbf{\hat{X}'(I-H)})}{diag(\mathbf{(I-H)X}\mathbf{W}^{-1}\mathbf{X'(I-H)})}.
</annotation></semantics></math> To display the fit measures, we create
a <code>biplot</code> object with the measures added by the function
<code><a href="../reference/fit.measures.html">fit.measures()</a></code> and call <code><a href="https://rdrr.io/r/base/summary.html" class="external-link">summary()</a></code>.</p>
<div class="sourceCode" id="cb10"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">obj</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/biplot.html">biplot</a></span><span class="op">(</span><span class="va">state.x77</span>, scaled <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span> <span class="op">|&gt;</span> </span>
<span>       <span class="fu"><a href="../reference/CVA.html">CVA</a></span><span class="op">(</span>classes <span class="op">=</span> <span class="va">state.division</span><span class="op">)</span> <span class="op">|&gt;</span> </span>
<span>       <span class="fu"><a href="../reference/fit.measures.html">fit.measures</a></span><span class="op">(</span><span class="op">)</span> <span class="op">|&gt;</span></span>
<span>       <span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html" class="external-link">plot</a></span><span class="op">(</span><span class="op">)</span></span></code></pre></div>
<p><img src="Class_separation_files/figure-html/unnamed-chunk-10-1.png" width="672"></p>
<div class="sourceCode" id="cb11"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/summary.html" class="external-link">summary</a></span> <span class="op">(</span><span class="va">obj</span><span class="op">)</span></span>
<span><span class="co">#&gt; Object of class biplot, based on 50 samples and 8 variables.</span></span>
<span><span class="co">#&gt; 8 numeric variables.</span></span>
<span><span class="co">#&gt; 9 classes: New England Middle Atlantic South Atlantic East South Central West South Central East North Central West North Central Mountain Pacific </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Quality of fit of canonical variables in 2 dimension(s) = 70.7% </span></span>
<span><span class="co">#&gt; Quality of fit of original variables in 2 dimension(s) = 70.5% </span></span>
<span><span class="co">#&gt; Adequacy of variables in 2 dimension(s):</span></span>
<span><span class="co">#&gt; Population     Income Illiteracy   Life Exp     Murder    HS Grad      Frost </span></span>
<span><span class="co">#&gt; 0.41716176 0.15621549 0.16136381 0.09759664 0.19426796 0.55332679 0.50497634 </span></span>
<span><span class="co">#&gt;       Area </span></span>
<span><span class="co">#&gt; 0.40661470 </span></span>
<span><span class="co">#&gt; Axis predictivity in 2 dimension(s):</span></span>
<span><span class="co">#&gt; Population     Income Illiteracy   Life Exp     Murder    HS Grad      Frost </span></span>
<span><span class="co">#&gt;  0.1859124  0.4019427  0.8195756  0.6925389  0.7685373  0.9506355  0.7819324 </span></span>
<span><span class="co">#&gt;       Area </span></span>
<span><span class="co">#&gt;  0.8458143 </span></span>
<span><span class="co">#&gt; Class predictivity in 2 dimension(s):</span></span>
<span><span class="co">#&gt;        New England    Middle Atlantic     South Atlantic East South Central </span></span>
<span><span class="co">#&gt;          0.7922047          0.6570417          0.8191791          0.8777759 </span></span>
<span><span class="co">#&gt; West South Central East North Central West North Central           Mountain </span></span>
<span><span class="co">#&gt;          0.7416085          0.6370315          0.3265978          0.6825966 </span></span>
<span><span class="co">#&gt;            Pacific </span></span>
<span><span class="co">#&gt;          0.6700194 </span></span>
<span><span class="co">#&gt; Within class axis predictivity in 2 dimension(s):</span></span>
<span><span class="co">#&gt; Population     Income Illiteracy   Life Exp     Murder    HS Grad      Frost </span></span>
<span><span class="co">#&gt; 0.04212318 0.09357501 0.25675620 0.19900223 0.29474972 0.75215233 0.31027358 </span></span>
<span><span class="co">#&gt;       Area </span></span>
<span><span class="co">#&gt; 0.12741853 </span></span>
<span><span class="co">#&gt; Within class sample predictivity in 2 dimension(s):</span></span>
<span><span class="co">#&gt;        Alabama         Alaska        Arizona       Arkansas     California </span></span>
<span><span class="co">#&gt;    0.722548912    0.163442379    0.333341120    0.268976273    0.229139828 </span></span>
<span><span class="co">#&gt;       Colorado    Connecticut       Delaware        Florida        Georgia </span></span>
<span><span class="co">#&gt;    0.264963758    0.082284385    0.593415987    0.461070888    0.636531435 </span></span>
<span><span class="co">#&gt;         Hawaii          Idaho       Illinois        Indiana           Iowa </span></span>
<span><span class="co">#&gt;    0.015640188    0.113711473    0.338612599    0.389208196    0.507060148 </span></span>
<span><span class="co">#&gt;         Kansas       Kentucky      Louisiana          Maine       Maryland </span></span>
<span><span class="co">#&gt;    0.784831952    0.314119027    0.078465054    0.008388471    0.306141816 </span></span>
<span><span class="co">#&gt;  Massachusetts       Michigan      Minnesota    Mississippi       Missouri </span></span>
<span><span class="co">#&gt;    0.076563044    0.218470793    0.645446212    0.046129058    0.710971640 </span></span>
<span><span class="co">#&gt;        Montana       Nebraska         Nevada  New Hampshire     New Jersey </span></span>
<span><span class="co">#&gt;    0.086279776    0.810374638    0.090490164    0.298187909    0.003496353 </span></span>
<span><span class="co">#&gt;     New Mexico       New York North Carolina   North Dakota           Ohio </span></span>
<span><span class="co">#&gt;    0.007134343    0.024268121    0.422776032    0.446240464    0.277262145 </span></span>
<span><span class="co">#&gt;       Oklahoma         Oregon   Pennsylvania   Rhode Island South Carolina </span></span>
<span><span class="co">#&gt;    0.450104680    0.108636860    0.033945796    0.415029328    0.261568299 </span></span>
<span><span class="co">#&gt;   South Dakota      Tennessee          Texas           Utah        Vermont </span></span>
<span><span class="co">#&gt;    0.134881180    0.247921823    0.110537439    0.500454605    0.159941068 </span></span>
<span><span class="co">#&gt;       Virginia     Washington  West Virginia      Wisconsin        Wyoming </span></span>
<span><span class="co">#&gt;    0.310439564    0.030877305    0.066303623    0.295499472    0.474458397</span></span></code></pre></div>
<p>The call to <code><a href="../reference/biplot.html">biplot()</a></code>, <code><a href="../reference/CVA.html">CVA()</a></code> and
<code><a href="../reference/fit.measures.html">fit.measures()</a></code> is required to (a) create an object of class
<code>biplot</code>, (b) extend the object to class <code>CVA</code> and
(c) compute the fit measures. The call to the function
<code><a href="https://rdrr.io/r/graphics/plot.default.html" class="external-link">plot()</a></code> is optional. It is further possible to select which
fit measures to display in the <code><a href="https://rdrr.io/r/base/summary.html" class="external-link">summary()</a></code> function where all
measures default to <code>TRUE</code>.</p>
<div class="sourceCode" id="cb12"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">obj</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/biplot.html">biplot</a></span><span class="op">(</span><span class="va">state.x77</span>, scaled <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span> <span class="op">|&gt;</span> </span>
<span>       <span class="fu"><a href="../reference/CVA.html">CVA</a></span><span class="op">(</span>classes <span class="op">=</span> <span class="va">state.region</span><span class="op">)</span> <span class="op">|&gt;</span> </span>
<span>       <span class="fu"><a href="../reference/fit.measures.html">fit.measures</a></span><span class="op">(</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/summary.html" class="external-link">summary</a></span> <span class="op">(</span><span class="va">obj</span>, adequacy <span class="op">=</span> <span class="cn">FALSE</span>, within.class.axis.predictivity <span class="op">=</span> <span class="cn">FALSE</span>,</span>
<span>         within.class.sample.predictivity <span class="op">=</span> <span class="cn">FALSE</span><span class="op">)</span></span>
<span><span class="co">#&gt; Object of class biplot, based on 50 samples and 8 variables.</span></span>
<span><span class="co">#&gt; 8 numeric variables.</span></span>
<span><span class="co">#&gt; 4 classes: Northeast South North Central West </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Quality of fit of canonical variables in 2 dimension(s) = 91.9% </span></span>
<span><span class="co">#&gt; Quality of fit of original variables in 2 dimension(s) = 95.3% </span></span>
<span><span class="co">#&gt; Axis predictivity in 2 dimension(s):</span></span>
<span><span class="co">#&gt; Population     Income Illiteracy   Life Exp     Murder    HS Grad      Frost </span></span>
<span><span class="co">#&gt;  0.9873763  0.9848608  0.8757913  0.9050208  0.9955088  0.9970346  0.9558192 </span></span>
<span><span class="co">#&gt;       Area </span></span>
<span><span class="co">#&gt;  0.9344651 </span></span>
<span><span class="co">#&gt; Class predictivity in 2 dimension(s):</span></span>
<span><span class="co">#&gt;     Northeast         South North Central          West </span></span>
<span><span class="co">#&gt;     0.8031465     0.9985089     0.6449906     0.9988469</span></span></code></pre></div>
</div>
</div>
</div>
</div>
<div class="section level2">
<h2 id="additional-cva-dimensions">Additional CVA dimensions<a class="anchor" aria-label="anchor" href="#additional-cva-dimensions"></a>
</h2>
<p>It was mentioned that the eigen equation (1) has
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>m</mi><mi>i</mi><mi>n</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>p</mi><mo>,</mo><mi>G</mi><mo>−</mo><mn>1</mn><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">min(p, G-1)</annotation></semantics></math>
non-zero eigenvalues. This implies that the CVA biplot for
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>G</mi><mo>=</mo><mn>2</mn></mrow><annotation encoding="application/x-tex">G=2</annotation></semantics></math>
groups, reduces to a single dimension. If we write</p>
<p><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>𝐌</mi><mo>=</mo><mrow><mo stretchy="true" form="prefix">[</mo><mtable><mtr><mtd columnalign="center" style="text-align: center"><msub><mi>𝐦</mi><mn>1</mn></msub></mtd><mtd columnalign="center" style="text-align: center"><msup><mi>𝐌</mi><mo>*</mo></msup></mtd></mtr></mtable><mo stretchy="true" form="postfix">]</mo></mrow></mrow><annotation encoding="application/x-tex">
\mathbf{M} = \begin{bmatrix}
             \mathbf{m}_1 &amp; \mathbf{M}^*
             \end{bmatrix}
</annotation></semantics></math> the columns of
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msup><mi>𝐌</mi><mo>*</mo></msup><annotation encoding="application/x-tex">\mathbf{M}^*</annotation></semantics></math>
forms a basis for the orthogonal complement of the canonical space
defined by
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>𝐦</mi><annotation encoding="application/x-tex">\mathbf{m}</annotation></semantics></math>_1.
The argument <code>low.dim</code> determines how to uniquely define the
second and third dimensions. By default
<code>low.dim = "sample.opt"</code> which selects the dimensions by
minimising total squared reconstruction error for samples.</p>
<p>The representation of the canonical variates
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mover><mi>𝐙</mi><mo accent="true">‾</mo></mover><mo>=</mo><mover><mi>𝐗</mi><mo accent="true">‾</mo></mover><msub><mi>𝐦</mi><mn>1</mn></msub></mrow><annotation encoding="application/x-tex">\bar{\mathbf{Z}} = \bar{\mathbf{X}}\mathbf{m}_1</annotation></semantics></math>
are exact in the first dimension, but not the representation of the
individual samples
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>𝐙</mi><mo>=</mo><mi>𝐗</mi><msub><mi>𝐦</mi><mn>1</mn></msub></mrow><annotation encoding="application/x-tex">{\mathbf{Z}} = {\mathbf{X}}\mathbf{m}_1</annotation></semantics></math>.
If we define
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mover><mi>𝐗</mi><mo accent="true">̂</mo></mover><mo>=</mo><mrow><mi>𝐗</mi><mi>𝐌</mi><mi>𝐉</mi></mrow><msup><mi>𝐌</mi><mrow><mi>−</mi><mn>1</mn></mrow></msup></mrow><annotation encoding="application/x-tex">\mathbf{\hat{X}} = \mathbf{XMJ}\mathbf{M}^{-1}</annotation></semantics></math>
with
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>𝐉</mi><annotation encoding="application/x-tex">\mathbf{J}</annotation></semantics></math>
a square matrix of zeros except for a
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mn>1</mn><annotation encoding="application/x-tex">1</annotation></semantics></math>
in the first diagonal position, then the total square reconstruction
error for samples is given by</p>
<p><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>T</mi><mi>S</mi><mi>R</mi><mi>E</mi><mi>S</mi><mo>=</mo><mi>t</mi><mi>r</mi><mrow><mrow><mo stretchy="true" form="prefix">(</mo><mi>𝐗</mi><mo>−</mo><mover><mi>𝐗</mi><mo accent="true">̂</mo></mover><mo stretchy="true" form="postfix">)</mo></mrow><mi>′</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>𝐗</mi><mo>−</mo><mover><mi>𝐗</mi><mo accent="true">̂</mo></mover><mo stretchy="true" form="postfix">)</mo></mrow></mrow><mi>.</mi></mrow><annotation encoding="application/x-tex">
TSRES = tr{(\mathbf{X}-\mathbf{\hat{X}})'(\mathbf{X}-\mathbf{\hat{X}})}.
</annotation></semantics></math> Define
<math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>𝐌</mi><mrow><mi>−</mi><mn>1</mn></mrow></msup><mo>=</mo><mrow><mo stretchy="true" form="prefix">[</mo><mtable><mtr><mtd columnalign="center" style="text-align: center"><msup><mi>𝐌</mi><mrow><mo stretchy="true" form="prefix">(</mo><mn>1</mn><mo stretchy="true" form="postfix">)</mo></mrow></msup><mo>:</mo><mrow><mo stretchy="true" form="prefix">(</mo><mi>G</mi><mo>−</mo><mn>1</mn><mo stretchy="true" form="postfix">)</mo></mrow><mo>×</mo><mi>p</mi></mtd></mtr><mtr><mtd columnalign="center" style="text-align: center"><msup><mi>𝐌</mi><mrow><mo stretchy="true" form="prefix">(</mo><mn>2</mn><mo stretchy="true" form="postfix">)</mo></mrow></msup><mo>:</mo><mrow><mo stretchy="true" form="prefix">(</mo><mi>p</mi><mo>−</mo><mi>G</mi><mo>+</mo><mn>1</mn><mo stretchy="true" form="postfix">)</mo></mrow><mo>×</mo><mi>p</mi></mtd></mtr></mtable><mo stretchy="true" form="postfix">]</mo></mrow></mrow><annotation encoding="application/x-tex">
\mathbf{M}^{-1} = \begin{bmatrix}
\mathbf{M}^{(1)}:(G-1) \times p \\
\mathbf{M}^{(2)}: (p-G+1) \times p
\end{bmatrix}
</annotation></semantics></math></p>
<p>then
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>T</mi><mi>S</mi><mi>R</mi><mi>E</mi><mi>S</mi></mrow><annotation encoding="application/x-tex">TSRES</annotation></semantics></math>
is minimised when</p>
<p><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>𝐌</mi><mrow><mi>o</mi><mi>p</mi><mi>t</mi></mrow></msup><mo>=</mo><mrow><mo stretchy="true" form="prefix">[</mo><mtable><mtr><mtd columnalign="center" style="text-align: center"><msub><mi>𝐌</mi><mn>1</mn></msub></mtd><mtd columnalign="center" style="text-align: center"><msup><mi>𝐌</mi><mo>*</mo></msup><mi>𝐕</mi></mtd></mtr></mtable><mo stretchy="true" form="postfix">]</mo></mrow></mrow><annotation encoding="application/x-tex">
  \mathbf{M}^{opt} = \begin{bmatrix}
  \mathbf{M}_1 &amp; \mathbf{M}^*\mathbf{V}
  \end{bmatrix}
</annotation></semantics></math></p>
<p>where where
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>𝐕</mi><annotation encoding="application/x-tex">\mathbf{V}</annotation></semantics></math>
is the matrix of right singular vectors of
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>𝐌</mi><mrow><mo stretchy="true" form="prefix">(</mo><mn>2</mn><mo stretchy="true" form="postfix">)</mo></mrow></msup><msup><mi>𝐌</mi><mrow><mrow><mo stretchy="true" form="prefix">(</mo><mn>2</mn><mo stretchy="true" form="postfix">)</mo></mrow><mi>′</mi></mrow></msup></mrow><annotation encoding="application/x-tex">\mathbf{M}^{(2)}\mathbf{M}^{(2)'}</annotation></semantics></math>.</p>
<div class="sourceCode" id="cb13"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">state.2group</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/ifelse.html" class="external-link">ifelse</a></span><span class="op">(</span><span class="va">state.division</span> <span class="op">==</span> <span class="st">"New England"</span> <span class="op">|</span> </span>
<span>                       <span class="va">state.division</span> <span class="op">==</span> <span class="st">"Middle Atlantic"</span>  <span class="op">|</span></span>
<span>                       <span class="va">state.division</span> <span class="op">==</span> <span class="st">"South Atlantic"</span> <span class="op">|</span></span>
<span>                       <span class="va">state.division</span> <span class="op">==</span> <span class="st">"Pacific"</span>,</span>
<span>                       <span class="st">"Coastal"</span>, <span class="st">"Central"</span><span class="op">)</span></span>
<span><span class="fu"><a href="../reference/biplot.html">biplot</a></span> <span class="op">(</span><span class="va">state.x77</span><span class="op">)</span> <span class="op">|&gt;</span> <span class="fu"><a href="../reference/CVA.html">CVA</a></span> <span class="op">(</span><span class="va">state.2group</span><span class="op">)</span> <span class="op">|&gt;</span> <span class="fu"><a href="../reference/legend.type.html">legend.type</a></span><span class="op">(</span>means<span class="op">=</span><span class="cn">TRUE</span><span class="op">)</span> <span class="op">|&gt;</span> <span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html" class="external-link">plot</a></span><span class="op">(</span><span class="op">)</span></span>
<span><span class="co">#&gt; Warning in CVA.biplot(biplot(state.x77), state.2group): The dimension of the</span></span>
<span><span class="co">#&gt; canonical space &lt; dim.biplot sample.opt method used for additional</span></span>
<span><span class="co">#&gt; dimension(s).</span></span></code></pre></div>
<p><img src="Class_separation_files/figure-html/unnamed-chunk-12-1.png" width="672"></p>
<p><span class="citation">le Roux and Gardner-Lubbe (2024)</span>
discuss an alternative method for obtaining additional dimensions. When
assuming underlying normal distributions, the Bhattacharyya distance can
be optimised. This method is specific to the two class case and cannot
be utilised to find a third dimension in a 3D CVA biplot with three
classes.</p>
<div class="sourceCode" id="cb14"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="../reference/biplot.html">biplot</a></span> <span class="op">(</span><span class="va">state.x77</span><span class="op">)</span> <span class="op">|&gt;</span> <span class="fu"><a href="../reference/CVA.html">CVA</a></span> <span class="op">(</span><span class="va">state.2group</span>, low.dim<span class="op">=</span><span class="st">"Bha"</span><span class="op">)</span> <span class="op">|&gt;</span> <span class="fu"><a href="../reference/legend.type.html">legend.type</a></span><span class="op">(</span>means<span class="op">=</span><span class="cn">TRUE</span><span class="op">)</span> <span class="op">|&gt;</span> <span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html" class="external-link">plot</a></span><span class="op">(</span><span class="op">)</span></span>
<span><span class="co">#&gt; Warning in CVA.biplot(biplot(state.x77), state.2group, low.dim = "Bha"): The</span></span>
<span><span class="co">#&gt; dimension of the canonical space &lt; dim.biplot Bhattacharyya.dist method used</span></span>
<span><span class="co">#&gt; for additional dimension(s).</span></span></code></pre></div>
<p><img src="Class_separation_files/figure-html/unnamed-chunk-13-1.png" width="672"></p>
</div>
<div class="section level2">
<h2 id="analysis-of-distance-aod">Analysis of Distance (AoD)<a class="anchor" aria-label="anchor" href="#analysis-of-distance-aod"></a>
</h2>
<p>Similar to the variance decomposition in CVA, analysis of distance
decomposes the total sum of squared distances into a sum of squared
distances between class means component and a sum of squared distances
within classes component.</p>
<p>Consider any Euclidean embeddable distance metric
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>ψ</mi><mrow><mi>i</mi><mi>j</mi></mrow></msub><mo>=</mo><mi>ψ</mi><mrow><mo stretchy="true" form="prefix">(</mo><msub><mi>𝐱</mi><mi>i</mi></msub><mo>,</mo><msub><mi>𝐱</mi><mi>j</mi></msub><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">\psi_{ij}=\psi(\mathbf{x}_i,\mathbf{x}_j)</annotation></semantics></math>.
For a Euclidean embeddable metric it is possible to find high
dimensional coordinates
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>𝐲</mi><mi>i</mi></msub><annotation encoding="application/x-tex">\mathbf{y}_i</annotation></semantics></math>
and
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>𝐲</mi><mi>j</mi></msub><annotation encoding="application/x-tex">\mathbf{y}_j</annotation></semantics></math>
such that the Euclidean distance between
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>𝐲</mi><mi>i</mi></msub><annotation encoding="application/x-tex">\mathbf{y}_i</annotation></semantics></math>
and
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>𝐲</mi><mi>j</mi></msub><annotation encoding="application/x-tex">\mathbf{y}_j</annotation></semantics></math>
is equal to
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>ψ</mi><mrow><mi>i</mi><mi>j</mi></mrow></msub><annotation encoding="application/x-tex">\psi_{ij}</annotation></semantics></math>.
Let the matrix
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mover><mi>𝚿</mi><mo accent="true">̃</mo></mover><annotation encoding="application/x-tex">\mathbf{\tilde\Psi}</annotation></semantics></math>
contain the values
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>−</mi><mfrac><mn>1</mn><mn>2</mn></mfrac><mrow></mrow><msubsup><mi>ψ</mi><mrow><mi>i</mi><mi>j</mi></mrow><mn>2</mn></msubsup></mrow><annotation encoding="application/x-tex">-\frac{1}2{}\psi_{ij}^2</annotation></semantics></math>
and similarly
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mover><mi>𝚫</mi><mo accent="true">̃</mo></mover><annotation encoding="application/x-tex">\mathbf{\tilde\Delta}</annotation></semantics></math>
the values
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>−</mi><mfrac><mn>1</mn><mn>2</mn></mfrac><mrow></mrow><msubsup><mi>δ</mi><mrow><mi>h</mi><mi>k</mi></mrow><mn>2</mn></msubsup></mrow><annotation encoding="application/x-tex">-\frac{1}2{}\delta_{hk}^2</annotation></semantics></math>
where
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>δ</mi><mrow><mi>h</mi><mi>k</mi></mrow></msub><annotation encoding="application/x-tex">\delta_{hk}</annotation></semantics></math>
represent the distance between class means
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>h</mi><annotation encoding="application/x-tex">h</annotation></semantics></math>
and
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>k</mi><annotation encoding="application/x-tex">k</annotation></semantics></math>.</p>
<p><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>𝐓</mi><mo>=</mo><mi>𝐁</mi><mo>+</mo><mi>𝐖</mi></mrow><annotation encoding="application/x-tex">
\mathbf{T} = \mathbf{B} + \mathbf{W}
</annotation></semantics></math></p>
<p><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mrow><mn>𝟏</mn><mi mathvariant="bold">′</mi><mover><mi>𝚿</mi><mo accent="true">̃</mo></mover><mn>𝟏</mn></mrow><mo>=</mo><mrow><mi>𝐧</mi><mi mathvariant="bold">′</mi><mover><mi>𝚫</mi><mo accent="true">̃</mo></mover><mi>𝐧</mi></mrow><mo>+</mo><munderover><mo>∑</mo><mrow><mi>k</mi><mo>=</mo><mn>1</mn></mrow><mi>G</mi></munderover><mfrac><mi>n</mi><msub><mi>n</mi><mi>k</mi></msub></mfrac><msub><mi>𝐠</mi><mi>k</mi></msub><mi>′</mi><mover><mi>𝚿</mi><mo accent="true">̃</mo></mover><msub><mi>𝐠</mi><mi>k</mi></msub></mrow><annotation encoding="application/x-tex">
\mathbf{1'\tilde\Psi1} = \mathbf{n'\tilde\Delta n} + \sum_{k=1}^{G} \frac{n}{n_k} \mathbf{g}_k'\mathbf{\tilde\Psi}\mathbf{g}_k
</annotation></semantics></math> where
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>𝐧</mi><mo>=</mo><mrow><mrow><mo stretchy="true" form="prefix" mathvariant="bold">(</mo><mi>𝐆</mi><mi mathvariant="bold">′</mi><mi>𝐆</mi><mo stretchy="true" form="postfix" mathvariant="bold">)</mo></mrow><mn>𝟏</mn></mrow></mrow><annotation encoding="application/x-tex">\mathbf{n}=\mathbf{(G'G)1}</annotation></semantics></math>.
Thus, AoD differs from CVA in allowing any Euclidean embeddable measure
of inter-class distance. As with CVA, these distances may be represented
in maps with point representing the class means, supplemented by
additional points representing the within-group variation. Principal
coordinate analysis is performed, only on the
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>G</mi><mo>×</mo><mi>G</mi></mrow><annotation encoding="application/x-tex">G \times G</annotation></semantics></math>
matrix
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mover><mi>𝚫</mi><mo accent="true">̃</mo></mover><annotation encoding="application/x-tex">\mathbf{\tilde\Delta}</annotation></semantics></math>.</p>
<div class="sourceCode" id="cb15"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="../reference/biplot.html">biplot</a></span><span class="op">(</span><span class="va">state.x77</span>, scaled <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span> <span class="op">|&gt;</span> <span class="fu"><a href="../reference/AoD.html">AoD</a></span><span class="op">(</span>classes <span class="op">=</span> <span class="va">state.region</span><span class="op">)</span> <span class="op">|&gt;</span> <span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html" class="external-link">plot</a></span><span class="op">(</span><span class="op">)</span></span></code></pre></div>
<p><img src="Class_separation_files/figure-html/unnamed-chunk-14-1.png" width="672"></p>
<p>By default linear regression biplot axes are fitted to the plot.
Alternatively, spline axes can be constructed.</p>
<div class="sourceCode" id="cb16"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="../reference/biplot.html">biplot</a></span><span class="op">(</span><span class="va">state.x77</span>, scaled <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span> <span class="op">|&gt;</span> <span class="fu"><a href="../reference/AoD.html">AoD</a></span><span class="op">(</span>classes <span class="op">=</span> <span class="va">state.region</span>, axes <span class="op">=</span> <span class="st">"splines"</span><span class="op">)</span> <span class="op">|&gt;</span> <span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html" class="external-link">plot</a></span><span class="op">(</span><span class="op">)</span></span></code></pre></div>
<p><img src="Class_separation_files/figure-html/unnamed-chunk-15-1.png" width="672"></p>
<pre><code><span><span class="co">#&gt; Calculating spline axis for variable 1 </span></span>
<span><span class="co">#&gt; Calculating spline axis for variable 2 </span></span>
<span><span class="co">#&gt; Calculating spline axis for variable 3 </span></span>
<span><span class="co">#&gt; Calculating spline axis for variable 4 </span></span>
<span><span class="co">#&gt; Calculating spline axis for variable 5 </span></span>
<span><span class="co">#&gt; Calculating spline axis for variable 6 </span></span>
<span><span class="co">#&gt; Calculating spline axis for variable 7 </span></span>
<span><span class="co">#&gt; Calculating spline axis for variable 8</span></span></code></pre>
<p>As an illustration of a Euclidean embeddable distance metric, other
than Euclidean distance itself, we can construct an AoD biplot with the
square root of the Manhattan distance.</p>
<div class="sourceCode" id="cb18"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="../reference/biplot.html">biplot</a></span><span class="op">(</span><span class="va">state.x77</span>, scaled <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span> <span class="op">|&gt;</span> </span>
<span>  <span class="fu"><a href="../reference/AoD.html">AoD</a></span><span class="op">(</span>classes <span class="op">=</span> <span class="va">state.region</span>, axes <span class="op">=</span> <span class="st">"splines"</span>, dist.func<span class="op">=</span><span class="va">sqrtManhattan</span><span class="op">)</span> <span class="op">|&gt;</span> <span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html" class="external-link">plot</a></span><span class="op">(</span><span class="op">)</span></span></code></pre></div>
<p><img src="Class_separation_files/figure-html/unnamed-chunk-16-1.png" width="672"></p>
<pre><code><span><span class="co">#&gt; Calculating spline axis for variable 1 </span></span>
<span><span class="co">#&gt; Calculating spline axis for variable 2 </span></span>
<span><span class="co">#&gt; Calculating spline axis for variable 3 </span></span>
<span><span class="co">#&gt; Calculating spline axis for variable 4 </span></span>
<span><span class="co">#&gt; Calculating spline axis for variable 5 </span></span>
<span><span class="co">#&gt; Calculating spline axis for variable 6 </span></span>
<span><span class="co">#&gt; Calculating spline axis for variable 7 </span></span>
<span><span class="co">#&gt; Calculating spline axis for variable 8</span></span></code></pre>
</div>
<div class="section level2">
<h2 class="unnumbered" id="references">References<a class="anchor" aria-label="anchor" href="#references"></a>
</h2>
<div id="refs" class="references csl-bib-body hanging-indent" entry-spacing="0">
<div id="ref-leRouxLubbe2024" class="csl-entry">
le Roux, N. J, and S. Gardner-Lubbe. 2024. <span>“A Two-Group Canonical
Variate Analysis Biplot for an Optimal Display of Bothmeans and
Cases.”</span> <em>Advances in Data Analysis and Classification</em>.
</div>
</div>
</div>
  </main><aside class="col-md-3"><nav id="toc" aria-label="Table of contents"><h2>On this page</h2>
    </nav></aside>
</div>



    <footer><div class="pkgdown-footer-left">
  <p>Developed by Sugnet Lubbe, Niël le Roux, Johané Nienkemper-Swanepoel, Raeesa Ganey, Ruan Buys, Zoë-Mae Adams, Peter Manefeldt.</p>
</div>

<div class="pkgdown-footer-right">
  <p>Site built with <a href="https://pkgdown.r-lib.org/" class="external-link">pkgdown</a> 2.1.2.</p>
</div>

    </footer>
</div>





  </body>
</html>
